{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9b21ff1f",
   "metadata": {},
   "source": [
    "# Core 4.1 Batch Pipelines - Setup Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19bad483",
   "metadata": {},
   "source": [
    "In this section, we will show how to write a batch pipeline so that it can be executed via an MLRun Project."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2510f9d",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44fedcdd",
   "metadata": {},
   "source": [
    "### References"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28e6f70c",
   "metadata": {},
   "source": [
    "Much of the following content is derived from the official documenation:\n",
    "- [Project workflows and automation](https://docs.mlrun.org/en/latest/projects/workflows.html)\n",
    "- [Projects](https://docs.mlrun.org/en/latest/projects/project.html)\n",
    "- [Functions](https://docs.mlrun.org/en/latest/runtimes/functions.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eff468b",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21bdc842",
   "metadata": {},
   "source": [
    "### Brining It All Together"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6796dde8",
   "metadata": {},
   "source": [
    "In previous sections, we covered MLRun Projects and Functions. Now, we will bring them together by creating a batch pipeline. This will allow us to use the MLRun Project to execute several Functions in a DAG using the Python SDK or CLI."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5992ea93",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80784acb",
   "metadata": {},
   "source": [
    "### Example Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaf77d54",
   "metadata": {},
   "source": [
    "In this example, we will create a project with 3 MLRun functions and a single pipeline that orchestrates them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9143e01f",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00cc499d",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28924696",
   "metadata": {},
   "source": [
    "In this example, we will create a project with 3 MLRun functions and a single pipeline that orchestrates them. The pipeline steps will be the following:\n",
    "- `get-data` - Get iris data from sklearn\n",
    "- `train-model` - Train model via sklearn\n",
    "- `deploy-model` - Deploy model to HTTP endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ad1b4c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 2022-06-23 19:45:53,179 [info] loaded project iguazio-academy from MLRun DB\n"
     ]
    }
   ],
   "source": [
    "import mlrun\n",
    "\n",
    "project = mlrun.get_or_create_project(\"iguazio-academy\", context=\"./\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c0547b0",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83f73e6a",
   "metadata": {},
   "source": [
    "### Add Functions to Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea8d421b",
   "metadata": {},
   "source": [
    "We have prepared the three pipeline steps outlined above: `get-data`, `train-model`, and `deploy-model`. Like we saw in [1.3 MLRun Projects](../1_mlrun_basics/1.3_mlrun_projects.ipynb), we can add the functions to a project like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9555c8ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<mlrun.runtimes.serving.ServingRuntime at 0x7fa3ff06ed10>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project.set_function(name='get-data', func='functions/get_data.py', kind='job', image='mlrun/mlrun')\n",
    "project.set_function(name='train-model', func='functions/train.py', kind='job', image='mlrun/mlrun')\n",
    "project.set_function(name='deploy-model', func='hub://v2_model_server')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96c61f24",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da2e0068",
   "metadata": {},
   "source": [
    "### Write Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4f7d72f",
   "metadata": {},
   "source": [
    "Next, we will define the pipeline that orchestrates the three comoponents. This pipeline will be very simple, however you can create very complex pipelines with branches, conditions, and more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a0e0e548",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting pipelines/training_pipeline.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile pipelines/training_pipeline.py\n",
    "from kfp import dsl\n",
    "import mlrun\n",
    "\n",
    "@dsl.pipeline(\n",
    "    name=\"batch-pipeline-academy\",\n",
    "    description=\"Example of batch pipeline for Iguazio Academy\"\n",
    ")\n",
    "def pipeline(label_column: str, test_size=0.2):\n",
    "    \n",
    "    # Ingest the data set\n",
    "    ingest = mlrun.run_function(\n",
    "        'get-data',\n",
    "        handler='prep_data',\n",
    "        params={'label_column': label_column},\n",
    "        outputs=[\"iris_dataset\"]\n",
    "    )\n",
    "    \n",
    "    # Train a model   \n",
    "    train = mlrun.run_function(\n",
    "        \"train-model\",\n",
    "        handler=\"train_model\",\n",
    "        inputs={\"dataset\": ingest.outputs[\"iris_dataset\"]},\n",
    "        params={\n",
    "            \"label_column\": label_column,\n",
    "            \"test_size\" : test_size\n",
    "        },\n",
    "        outputs=['model']\n",
    "    )\n",
    "    \n",
    "    # Deploy the model as a serverless function\n",
    "    deploy = mlrun.deploy_function(\n",
    "        \"deploy-model\",\n",
    "        models=[{\"key\": \"model\", \"model_path\": train.outputs[\"model\"]}]\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8903b4c3",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71f9f757",
   "metadata": {},
   "source": [
    "### Add Pipeline to Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd0586a5",
   "metadata": {},
   "source": [
    "Once our pipeline is defined, we can add it to our project just like we saw in [1.3 MLRun Projects](../1_mlrun_basics/1.3_mlrun_projects.ipynb):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a8aefa6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "project.set_workflow(name='train', workflow_path=\"pipelines/training_pipeline.py\")\n",
    "project.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f5c1b95",
   "metadata": {},
   "source": [
    "In the next sections we will execute the pipeline via Kubeflow Pipelines and in a local context"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "249bd5e3",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
