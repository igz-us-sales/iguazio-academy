{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Complex Graph - Multiple Models and Multiple Endpoints\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Setup Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 2022-06-10 23:41:10,527 [info] loaded project realtime-pipelines from MLRun DB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('realtime-pipelines', 'v3io:///projects/{{run.project}}/artifacts')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import mlrun\n",
    "import os\n",
    "\n",
    "# Create the project:\n",
    "project_name='realtime-pipelines'\n",
    "project_dir = os.path.abspath('./')\n",
    "project = mlrun.new_project(project_name, project_dir)\n",
    "\n",
    "# Set the environment:\n",
    "mlrun.set_environment(project=project.metadata.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Serving Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting dummy_model.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile dummy_model.py\n",
    "\n",
    "from typing import Any, Dict, List, Union\n",
    "import mlrun\n",
    "from mlrun.serving.v2_serving import V2ModelServer\n",
    "from datetime import datetime\n",
    "import psutil\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "class DummyModelServer(mlrun.serving.V2ModelServer):\n",
    "    def load(self):\n",
    "        \"\"\"load and initialize the model and/or other elements\"\"\"\n",
    "\n",
    "    def predict(self, body: dict) -> List:\n",
    "        \"\"\"Generate model predictions from sample.\"\"\"\n",
    "        print(\"+++++++++++++++++++ in Dummy Model Prediction ++++++++++++++++++++++\")\n",
    "        feats = np.asarray(body['inputs'])\n",
    "        print(f'feats shape === >>> {feats.shape}')\n",
    "        print(\"+++++++++++++++++++ out Dummy Model Prediction ++++++++++++++++++++++\")\n",
    "        print()\n",
    "        return feats.shape\n",
    "\n",
    "def postprocess(event):\n",
    "    print(\"+++++++++++++++++++ in Dummy Postprocess ++++++++++++++++++++++\")\n",
    "    print(f'Event keys === >>> {event.keys()}')\n",
    "    print(\"+++++++++++++++++++ out Dummy Postprocess ++++++++++++++++++++++\")\n",
    "    print()\n",
    "    return event\n",
    "\n",
    "def preprocess(event):\n",
    "    print(\"+++++++++++++++++++ in Dummy Preprocess ++++++++++++++++++++++\")\n",
    "    print(f'Event keys === >>> {event.keys()}')\n",
    "    print(\"+++++++++++++++++++ out Dummy Preprocess ++++++++++++++++++++++\")\n",
    "    print()\n",
    "    return event"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Serving Graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1 Serving function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "serving_function = mlrun.code_to_function(\n",
    "    \"model_routing\", \n",
    "    filename=\"./dummy_model.py\",\n",
    "    kind=\"serving\", \n",
    "    image=\"mlrun/mlrun\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 Set up multiple routes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_path = 'https://s3.wasabisys.com/iguazio/models/iris/model.pkl'\n",
    "path1 = models_path\n",
    "path2 = models_path\n",
    "path3 = models_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n",
       " -->\n",
       "<!-- Title: mlrun&#45;flow Pages: 1 -->\n",
       "<svg width=\"541pt\" height=\"222pt\"\n",
       " viewBox=\"0.00 0.00 540.51 222.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 218)\">\n",
       "<title>mlrun&#45;flow</title>\n",
       "<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-218 536.5092,-218 536.5092,4 -4,4\"/>\n",
       "<g id=\"clust1\" class=\"cluster\">\n",
       "<title>cluster_router</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"259.388,-46 259.388,-206 523.6107,-206 523.6107,-46 259.388,-46\"/>\n",
       "</g>\n",
       "<!-- _start -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>_start</title>\n",
       "<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"38.5476,-83.0493 40.698,-83.1479 42.8263,-83.2953 44.9236,-83.4913 46.9815,-83.7353 48.9917,-84.0266 50.9463,-84.3645 52.8377,-84.7479 54.6587,-85.1759 56.4025,-85.6472 58.0628,-86.1606 59.634,-86.7147 61.1107,-87.308 62.4882,-87.9388 63.7625,-88.6054 64.9302,-89.3059 65.9882,-90.0385 66.9343,-90.8012 67.7669,-91.5918 68.4849,-92.4082 69.0878,-93.2481 69.5758,-94.1093 69.9496,-94.9894 70.2102,-95.886 70.3595,-96.7965 70.3997,-97.7186 70.3334,-98.6497 70.1636,-99.5873 69.8937,-100.5287 69.5276,-101.4713 69.0691,-102.4127 68.5225,-103.3503 67.8923,-104.2814 67.1831,-105.2035 66.3996,-106.114 65.5464,-107.0106 64.6285,-107.8907 63.6504,-108.7519 62.617,-109.5918 61.5329,-110.4082 60.4024,-111.1988 59.2299,-111.9615 58.0197,-112.6941 56.7755,-113.3946 55.5012,-114.0612 54.2002,-114.692 52.8757,-115.2853 51.5309,-115.8394 50.1684,-116.3528 48.7908,-116.8241 47.4003,-117.2521 45.9989,-117.6355 44.5886,-117.9734 43.1708,-118.2647 41.7472,-118.5087 40.3189,-118.7047 38.8872,-118.8521 37.4531,-118.9507 36.0175,-119 34.5815,-119 33.146,-118.9507 31.7119,-118.8521 30.2801,-118.7047 28.8519,-118.5087 27.4282,-118.2647 26.0105,-117.9734 24.6001,-117.6355 23.1988,-117.2521 21.8083,-116.8241 20.4306,-116.3528 19.0681,-115.8394 17.7233,-115.2853 16.3989,-114.692 15.0979,-114.0612 13.8236,-113.3946 12.5794,-112.6941 11.3691,-111.9615 10.1967,-111.1988 9.0662,-110.4082 7.982,-109.5918 6.9486,-108.7519 5.9706,-107.8907 5.0526,-107.0106 4.1995,-106.114 3.4159,-105.2035 2.7067,-104.2814 2.0765,-103.3503 1.53,-102.4127 1.0715,-101.4713 .7053,-100.5287 .4355,-99.5873 .2657,-98.6497 .1993,-97.7186 .2395,-96.7965 .3888,-95.886 .6495,-94.9894 1.0232,-94.1093 1.5112,-93.2481 2.1141,-92.4082 2.8321,-91.5918 3.6647,-90.8012 4.6109,-90.0385 5.6689,-89.3059 6.8365,-88.6054 8.1108,-87.9388 9.4884,-87.308 10.9651,-86.7147 12.5362,-86.1606 14.1966,-85.6472 15.9404,-85.1759 17.7614,-84.7479 19.6528,-84.3645 21.6074,-84.0266 23.6176,-83.7353 25.6755,-83.4913 27.7728,-83.2953 29.901,-83.1479 32.0515,-83.0493 34.2154,-83 36.3837,-83 38.5476,-83.0493\"/>\n",
       "<text text-anchor=\"middle\" x=\"35.2995\" y=\"-97.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">start</text>\n",
       "</g>\n",
       "<!-- preprocess -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>preprocess</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"168.9935\" cy=\"-101\" rx=\"62.2891\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"168.9935\" y=\"-97.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">preprocess</text>\n",
       "</g>\n",
       "<!-- _start&#45;&gt;preprocess -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>_start&#45;&gt;preprocess</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M69.729,-101C77.9676,-101 87.0729,-101 96.3281,-101\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"96.3959,-104.5001 106.3959,-101 96.3958,-97.5001 96.3959,-104.5001\"/>\n",
       "</g>\n",
       "<!-- router -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>router</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"358.7281,-93.5442 358.7281,-108.4558 333.1154,-119 296.8936,-119 271.281,-108.4558 271.281,-93.5442 296.8936,-83 333.1154,-83 358.7281,-93.5442\"/>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"362.7379,-90.8677 362.7379,-111.1323 333.9103,-123 296.0987,-123 267.2712,-111.1323 267.2712,-90.8677 296.0987,-79 333.9103,-79 362.7379,-90.8677\"/>\n",
       "<text text-anchor=\"middle\" x=\"315.0045\" y=\"-97.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">router</text>\n",
       "</g>\n",
       "<!-- preprocess&#45;&gt;router -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>preprocess&#45;&gt;router</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M231.7627,-101C240.2251,-101 248.8746,-101 257.2444,-101\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"257.2835,-104.5001 267.2835,-101 257.2834,-97.5001 257.2835,-104.5001\"/>\n",
       "</g>\n",
       "<!-- router/model_1 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>router/model_1</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"465.5651\" cy=\"-72\" rx=\"50.0912\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"465.5651\" y=\"-68.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">model_1</text>\n",
       "</g>\n",
       "<!-- router&#45;&gt;router/model_1 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>router&#45;&gt;router/model_1</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M362.6428,-91.8242C378.0491,-88.8568 395.2491,-85.5438 411.1103,-82.4887\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"412.1503,-85.8528 421.3078,-80.5246 410.8263,-78.9792 412.1503,-85.8528\"/>\n",
       "</g>\n",
       "<!-- router/model_2 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>router/model_2</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"465.5651\" cy=\"-126\" rx=\"50.0912\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"465.5651\" y=\"-122.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">model_2</text>\n",
       "</g>\n",
       "<!-- router&#45;&gt;router/model_2 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>router&#45;&gt;router/model_2</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M362.6428,-108.9102C377.6958,-111.4096 394.4611,-114.1935 410.0169,-116.7764\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"409.5962,-120.2544 420.0345,-118.4398 410.7429,-113.349 409.5962,-120.2544\"/>\n",
       "</g>\n",
       "<!-- router/model_3 -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>router/model_3</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"465.5651\" cy=\"-180\" rx=\"50.0912\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"465.5651\" y=\"-176.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">model_3</text>\n",
       "</g>\n",
       "<!-- router&#45;&gt;router/model_3 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>router&#45;&gt;router/model_3</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M342.5566,-119.8167C358.5332,-130.2958 379.2632,-143.1702 398.621,-153 405.692,-156.5906 413.3577,-160.0558 420.8921,-163.2383\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"419.7309,-166.545 430.3108,-167.1064 422.3902,-160.0698 419.7309,-166.545\"/>\n",
       "</g>\n",
       "<!-- postprocess -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>postprocess</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"465.5651\" cy=\"-18\" rx=\"66.8882\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"465.5651\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">postprocess</text>\n",
       "</g>\n",
       "<!-- router&#45;&gt;postprocess -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>router&#45;&gt;postprocess</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M391.2346,-46.0049C393.7006,-44.6151 396.1662,-43.276 398.621,-42 403.0938,-39.6751 407.8426,-37.4814 412.6657,-35.436\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"414.0074,-38.6689 421.9792,-31.6902 411.3954,-32.1745 414.0074,-38.6689\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.dot.Digraph at 0x7f8e0734d490>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph = serving_function.set_topology(\"flow\", engine=\"async\")\n",
    "\n",
    "graph.add_step(handler=\"preprocess\", name=\"preprocess\")\n",
    "\n",
    "router = graph.add_step(\"*\", name=\"router\", after=\"preprocess\")\n",
    "router.add_route(\n",
    "    \"model_1\", \n",
    "    class_name=\"DummyModelServer\", \n",
    "    model_path=path1,\n",
    "    function='inference'\n",
    ")\n",
    "router.add_route(\n",
    "    \"model_2\", \n",
    "    class_name=\"DummyModelServer\", \n",
    "    model_path=path2,\n",
    "    function='inference'\n",
    ")\n",
    "router.add_route(\n",
    "    \"model_3\", \n",
    "    class_name=\"DummyModelServer\", \n",
    "    model_path=path3,\n",
    "    function='inference'\n",
    ")\n",
    "graph.add_step(handler=\"postprocess\", name=\"postprocess\", after=\"router\").respond()\n",
    "\n",
    "graph.plot(rankdir='LR')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Running Graph Local "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dummy_model import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test endpoint #1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 2022-06-10 23:41:42,028 [info] model model_1 was loaded\n",
      "> 2022-06-10 23:41:42,028 [info] model model_2 was loaded\n",
      "> 2022-06-10 23:41:42,029 [info] model model_3 was loaded\n",
      "> 2022-06-10 23:41:42,029 [info] Loaded ['model_1', 'model_2', 'model_3']\n",
      "+++++++++++++++++++ in Dummy Preprocess ++++++++++++++++++++++\n",
      "Event keys === >>> dict_keys(['inputs'])\n",
      "+++++++++++++++++++ out Dummy Preprocess ++++++++++++++++++++++\n",
      "\n",
      "+++++++++++++++++++ in Dummy Model Prediction ++++++++++++++++++++++\n",
      "feats shape === >>> (1, 1)\n",
      "+++++++++++++++++++ out Dummy Model Prediction ++++++++++++++++++++++\n",
      "\n",
      "+++++++++++++++++++ in Dummy Postprocess ++++++++++++++++++++++\n",
      "Event keys === >>> dict_keys(['id', 'model_name', 'outputs'])\n",
      "+++++++++++++++++++ out Dummy Postprocess ++++++++++++++++++++++\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'id': 'ee47fa2f7a734c528f5aab61a1d5bf95',\n",
       " 'model_name': 'model_1',\n",
       " 'outputs': (1, 1)}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "server = serving_function.to_mock_server(current_function=\"*\")\n",
    "response = server.test(path='/v2/models/model_1/predict', body={\"inputs\": [[1]]})\n",
    "server.wait_for_completion()\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test endpoint #2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 2022-06-10 23:41:44,128 [info] model model_1 was loaded\n",
      "> 2022-06-10 23:41:44,128 [info] model model_2 was loaded\n",
      "> 2022-06-10 23:41:44,129 [info] model model_3 was loaded\n",
      "> 2022-06-10 23:41:44,129 [info] Loaded ['model_1', 'model_2', 'model_3']\n",
      "+++++++++++++++++++ in Dummy Preprocess ++++++++++++++++++++++\n",
      "Event keys === >>> dict_keys(['inputs'])\n",
      "+++++++++++++++++++ out Dummy Preprocess ++++++++++++++++++++++\n",
      "\n",
      "+++++++++++++++++++ in Dummy Model Prediction ++++++++++++++++++++++\n",
      "feats shape === >>> (2, 2)\n",
      "+++++++++++++++++++ out Dummy Model Prediction ++++++++++++++++++++++\n",
      "\n",
      "+++++++++++++++++++ in Dummy Postprocess ++++++++++++++++++++++\n",
      "Event keys === >>> dict_keys(['id', 'model_name', 'outputs'])\n",
      "+++++++++++++++++++ out Dummy Postprocess ++++++++++++++++++++++\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'id': 'f031e59239a54c0d94b5a268a7e93c28',\n",
       " 'model_name': 'model_2',\n",
       " 'outputs': (2, 2)}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "server = serving_function.to_mock_server(current_function=\"*\")\n",
    "response = server.test(path='/v2/models/model_2/predict', body={\"inputs\": [[1, 1],[1, 1]]})\n",
    "server.wait_for_completion()\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test endpoint #3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 2022-06-10 23:41:46,699 [info] model model_1 was loaded\n",
      "> 2022-06-10 23:41:46,700 [info] model model_2 was loaded\n",
      "> 2022-06-10 23:41:46,700 [info] model model_3 was loaded\n",
      "> 2022-06-10 23:41:46,701 [info] Loaded ['model_1', 'model_2', 'model_3']\n",
      "+++++++++++++++++++ in Dummy Preprocess ++++++++++++++++++++++\n",
      "Event keys === >>> dict_keys(['inputs'])\n",
      "+++++++++++++++++++ out Dummy Preprocess ++++++++++++++++++++++\n",
      "\n",
      "+++++++++++++++++++ in Dummy Model Prediction ++++++++++++++++++++++\n",
      "feats shape === >>> (3, 3)\n",
      "+++++++++++++++++++ out Dummy Model Prediction ++++++++++++++++++++++\n",
      "\n",
      "+++++++++++++++++++ in Dummy Postprocess ++++++++++++++++++++++\n",
      "Event keys === >>> dict_keys(['id', 'model_name', 'outputs'])\n",
      "+++++++++++++++++++ out Dummy Postprocess ++++++++++++++++++++++\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'id': '6d1526b64faa45758203694ce2b85e5a',\n",
       " 'model_name': 'model_3',\n",
       " 'outputs': (3, 3)}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "server = serving_function.to_mock_server(current_function=\"*\")\n",
    "response = server.test(path='/v2/models/model_3/predict', body={\"inputs\": [[3, 3, 3], [3, 3, 3], [3, 3, 3]]})\n",
    "server.wait_for_completion()\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Deploy to cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "serving_function.apply(mlrun.platforms.auto_mount())\n",
    "serving_function.spec.min_replicas=1\n",
    "serving_function.spec.max_replicas=1\n",
    "# serving_function.spec.base_spec['spec']['loggerSinks'] = [{'level': 'info'}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 2022-06-10 23:41:51,736 [info] Starting remote function deploy\n",
      "2022-06-10 23:41:52  (info) Deploying function\n",
      "2022-06-10 23:41:52  (info) Building\n",
      "2022-06-10 23:41:52  (info) Staging files and preparing base images\n",
      "2022-06-10 23:41:52  (info) Building processor image\n",
      "2022-06-10 23:42:28  (info) Build complete\n",
      "2022-06-10 23:42:44  (info) Function deploy complete\n",
      "> 2022-06-10 23:42:44,285 [info] successfully deployed function: {'internal_invocation_urls': ['nuclio-realtime-pipelines-model-routing.default-tenant.svc.cluster.local:8080'], 'external_invocation_urls': ['realtime-pipelines-model-routing-realtime-pipelines.default-tenant.app.uss-sales-341.iguazio-cd1.com/']}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'http://realtime-pipelines-model-routing-realtime-pipelines.default-tenant.app.uss-sales-341.iguazio-cd1.com/'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "addr = serving_function.deploy()\n",
    "addr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test endpoint #1 in cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 2022-06-11 00:27:51,848 [info] invoking function: {'method': 'POST', 'path': 'http://nuclio-realtime-pipelines-model-routing.default-tenant.svc.cluster.local:8080/v2/models/model_1/predict'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'inputs': [[1]]}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "serving_function.invoke(path='/v2/models/model_1/predict', body={\"inputs\": [[1]]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test endpoint #2 in cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 2022-06-11 00:27:53,218 [info] invoking function: {'method': 'POST', 'path': 'http://nuclio-realtime-pipelines-model-routing.default-tenant.svc.cluster.local:8080/v2/models/model_2/predict'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'inputs': [[2]]}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "serving_function.invoke(path='/v2/models/model_2/predict', body={\"inputs\": [[2]]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test endpoint #3 in cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 2022-06-11 00:27:54,225 [info] invoking function: {'method': 'POST', 'path': 'http://nuclio-realtime-pipelines-model-routing.default-tenant.svc.cluster.local:8080/v2/models/model_3/predict'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'inputs': [[3]]}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "serving_function.invoke(path='/v2/models/model_3/predict', body={\"inputs\": [[3]]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
